{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('mnist_train.csv')\n",
    "mnist_test = pd.read_csv('mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of samples desired for each class in each dataset\n",
    "samples_per_class = 1000\n",
    "\n",
    "# Initialize two empty DataFrames to store the selected samples for each dataset\n",
    "selected_data_1 = pd.DataFrame()\n",
    "selected_data_2 = pd.DataFrame()\n",
    "\n",
    "# Iterate over each class label\n",
    "for class_label in range(10):  # 10 classes for digits 0-9\n",
    "    # Filter data for each class label\n",
    "    class_data = mnist_train[mnist_train['label'] == class_label]\n",
    "    \n",
    "    # Select the first 150 samples for the first dataset\n",
    "    first_samples = class_data.head(samples_per_class)\n",
    "    selected_data_1 = pd.concat([selected_data_1, first_samples])\n",
    "    \n",
    "    # Select the next 150 samples for the second dataset\n",
    "    next_samples = class_data.iloc[samples_per_class:samples_per_class*2]\n",
    "    selected_data_2 = pd.concat([selected_data_2, next_samples])\n",
    "\n",
    "# Resetting the index for both datasets\n",
    "selected_data_1 = selected_data_1.reset_index(drop=True)\n",
    "selected_data_2 = selected_data_2.reset_index(drop=True)\n",
    "# shuffle the rows of both datasets\n",
    "selected_data_1 = selected_data_1.sample(frac=1).reset_index(drop=True)\n",
    "selected_data_2 = selected_data_2.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_train = selected_data_1.drop('label', axis=1)\n",
    "model_1_label = selected_data_1['label']\n",
    "model_2_train = selected_data_2.drop('label', axis=1)\n",
    "model_2_label = selected_data_2['label']\n",
    "model_1_label = to_categorical(model_1_label,num_classes=10)\n",
    "model_2_label = to_categorical(model_2_label,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a common neural network architecture\n",
    "def create_neural_network(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=create_neural_network(model_1_train.shape[1], 10)\n",
    "model_2=create_neural_network(model_2_train.shape[1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fcaf86803a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the models\n",
    "model_1.fit(model_1_train, model_1_label, epochs=30, batch_size=32, validation_split=0.2, verbose=0)\n",
    "model_2.fit(model_2_train, model_2_label, epochs=30, batch_size=32, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1:  0.9372000098228455\n",
      "Accuracy of model 2:  0.9330999851226807\n"
     ]
    }
   ],
   "source": [
    "accuracy_1 = model_1.evaluate(mnist_test.drop('label', axis=1), to_categorical(mnist_test['label'], num_classes=10), verbose=0)[1]\n",
    "accuracy_2 = model_2.evaluate(mnist_test.drop('label', axis=1), to_categorical(mnist_test['label'], num_classes=10), verbose=0)[1]\n",
    "print('Accuracy of model 1: ', accuracy_1)\n",
    "print('Accuracy of model 2: ', accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = model_1.get_weights() \n",
    "weights_2 = model_2.get_weights()\n",
    "alpha = 0.5\n",
    "blended_weights = [alpha * w0 + (1 - alpha) * w1 for w0, w1 in zip(weights_1, weights_2)]\n",
    "model_1.set_weights(blended_weights)\n",
    "model_2.set_weights(blended_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model 1:  0.36230000853538513\n",
      "Accuracy of model 2:  0.36230000853538513\n"
     ]
    }
   ],
   "source": [
    "accuracy_1 = model_1.evaluate(mnist_test.drop('label', axis=1), to_categorical(mnist_test['label'], num_classes=10), verbose=0)[1]\n",
    "accuracy_2 = model_2.evaluate(mnist_test.drop('label', axis=1), to_categorical(mnist_test['label'], num_classes=10), verbose=0)[1]\n",
    "print('Accuracy of model 1: ', accuracy_1)\n",
    "print('Accuracy of model 2: ', accuracy_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
